package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"strconv"
	"strings"
	"time"

	"github.com/joho/godotenv"
	"gorm.io/gorm"
	"qiyuan-api-scripts/common"
)

// ä½¿ç”¨å…±äº«çš„Channelç±»å‹
type Channel = common.Channel

// ChannelBackupData å¤‡ä»½æ•°æ®ç»“æ„
type ChannelBackupData struct {
	ExportTime    string    `json:"export_time"`
	ExportVersion string    `json:"export_version"`
	TotalChannels int       `json:"total_channels"`
	DatabaseInfo  string    `json:"database_info"`
	Channels      []Channel `json:"channels"`
}

// ImportResult å¯¼å…¥ç»“æœ
type ImportResult struct {
	Total   int      `json:"total"`
	Success int      `json:"success"`
	Failed  int      `json:"failed"`
	Skipped int      `json:"skipped"`
	Errors  []string `json:"errors"`
}

// æ¸ é“ç±»å‹æ˜ å°„
var ChannelTypeNames = map[int]string{
	1: "OpenAI", 2: "API2D", 3: "Azure", 4: "CloseAI", 5: "CloseAI-SB",
	6: "OpenSB", 7: "AI-LS", 8: "AI-LS2", 9: "AI-LS3", 10: "AI360",
	11: "PaLM", 12: "Baidu", 13: "Zhipu", 14: "Ali", 15: "Xunfei",
	16: "AI-Proxy", 17: "OpenRouter", 18: "AI-LB", 19: "Replicate", 20: "Midjourney",
	21: "Anthropic", 22: "AWS", 23: "Cohere", 24: "Custom", 25: "Gemini",
	26: "Moonshot", 27: "Baichuan", 28: "Minimax", 29: "DeepSeek", 30: "Groq",
	31: "Ollama", 32: "PerplexityAI", 33: "Cloudflare", 34: "Lingyiwanwu", 35: "Doubao",
	36: "Tencent", 37: "Dify", 38: "Vertex", 39: "Coze", 40: "Jina",
	41: "Mistral", 42: "Siliconflow", 43: "Xinference", 44: "MidjourneyPlus", 45: "Suno",
	46: "Jimeng", 47: "Mokaai", 48: "Kling", 49: "XAI",
}

// æ¸ é“çŠ¶æ€æ˜ å°„
var ChannelStatusNames = map[int]string{
	0: "Unknown", 1: "Enabled", 2: "Manually Disabled", 3: "Auto Disabled",
}

func main() {
	var (
		action         = flag.String("action", "export", "æ“ä½œç±»å‹: export, import, backup, restore")
		sqlDSN         = flag.String("dsn", "", "æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸² (å¦‚æœä¸ºç©ºåˆ™å°è¯•ä»ç¯å¢ƒå˜é‡è·å–)")
		inputFile      = flag.String("input", "", "å¯¼å…¥æ–‡ä»¶è·¯å¾„ (ç”¨äºimport/restoreæ“ä½œ)")
		outputFile     = flag.String("output", "", "è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: channels_backup_TIMESTAMP.json)")
		format         = flag.String("format", "json", "è¾“å‡ºæ ¼å¼: json, csv, txt (ä»…ç”¨äºexport)")
		help           = flag.Bool("help", false, "æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
		verbose        = flag.Bool("verbose", false, "æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")
		maskKeys       = flag.Bool("mask-keys", true, "æ˜¯å¦éšè—æ•æ„Ÿçš„APIå¯†é’¥ä¿¡æ¯ (ä»…ç”¨äºexport)")
		filterType     = flag.Int("type", -1, "æŒ‰æ¸ é“ç±»å‹è¿‡æ»¤ (-1è¡¨ç¤ºå…¨éƒ¨)")
		filterStatus   = flag.Int("status", -1, "æŒ‰çŠ¶æ€è¿‡æ»¤ (-1è¡¨ç¤ºå…¨éƒ¨)")
		skipExisting   = flag.Bool("skip-existing", true, "å¯¼å…¥æ—¶è·³è¿‡å·²å­˜åœ¨çš„æ¸ é“")
		updateExisting = flag.Bool("update-existing", false, "å¯¼å…¥æ—¶æ›´æ–°å·²å­˜åœ¨çš„æ¸ é“")
		dryRun         = flag.Bool("dry-run", false, "æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…æ“ä½œæ•°æ®åº“")
	)

	flag.Parse()

	if *help {
		printHelpV1()
		return
	}

	// åŠ è½½ .env æ–‡ä»¶
	if err := godotenv.Load(); err != nil && *verbose {
		log.Printf("æœªæ‰¾åˆ° .env æ–‡ä»¶: %v", err)
	}

	// è·å–æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
	dbDSN := *sqlDSN
	if dbDSN == "" {
		dbDSN = os.Getenv("SQL_DSN")
	}
	if dbDSN == "" {
		// Docker Compose MySQL é»˜è®¤é…ç½®
		dbDSN = "root:123456@tcp(localhost:3306)/new-api"
	}

	if *verbose {
		log.Printf("ä½¿ç”¨æ•°æ®åº“è¿æ¥: %s", maskDSN(dbDSN))
		log.Printf("æ“ä½œç±»å‹: %s", *action)
	}

	// è¿æ¥æ•°æ®åº“
	db, err := common.ConnectDB(dbDSN)
	if err != nil {
		log.Fatalf("è¿æ¥æ•°æ®åº“å¤±è´¥: %v", err)
	}

	switch *action {
	case "export":
		err = handleExport(db, *outputFile, *format, *maskKeys, *filterType, *filterStatus, *verbose)
	case "import":
		err = handleImport(db, *inputFile, *skipExisting, *updateExisting, *dryRun, *verbose)
	case "backup":
		err = handleBackup(db, *outputFile, *verbose)
	case "restore":
		err = handleRestore(db, *inputFile, *dryRun, *verbose)
	default:
		log.Fatalf("æœªçŸ¥æ“ä½œç±»å‹: %s (æ”¯æŒ: export, import, backup, restore)", *action)
	}

	if err != nil {
		log.Fatalf("æ“ä½œå¤±è´¥: %v", err)
	}
}

func printHelpV1() {
	fmt.Println(`
æ¸ é“ç®¡ç†å·¥å…· - æ”¯æŒå¯¼å…¥å¯¼å‡ºåŠŸèƒ½
ç”¨æ³•: go run channel_manager.go -action=<æ“ä½œ> [é€‰é¡¹]

æ“ä½œç±»å‹:
  export   å¯¼å‡ºæ¸ é“æ•°æ®ï¼ˆå¯é€‰æ‹©æ ¼å¼ï¼‰
  import   å¯¼å…¥æ¸ é“æ•°æ®ï¼ˆä»JSONæ–‡ä»¶ï¼‰
  backup   å¤‡ä»½æ‰€æœ‰æ¸ é“æ•°æ®ï¼ˆåŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
  restore  æ¢å¤æ¸ é“æ•°æ®ï¼ˆä»å¤‡ä»½æ–‡ä»¶ï¼‰

é€šç”¨é€‰é¡¹:
  -dsn string         æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸² (é»˜è®¤ä»ç¯å¢ƒå˜é‡SQL_DSNè·å–)
  -verbose            æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  -help               æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

å¯¼å‡ºé€‰é¡¹:
  -output string      è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: channels_export_TIMESTAMP.json)
  -format string      è¾“å‡ºæ ¼å¼: json, csv, txt (é»˜è®¤: json)
  -mask-keys          æ˜¯å¦éšè—æ•æ„Ÿçš„APIå¯†é’¥ä¿¡æ¯ (é»˜è®¤: true)
  -type int           æŒ‰æ¸ é“ç±»å‹è¿‡æ»¤ (-1è¡¨ç¤ºå…¨éƒ¨, é»˜è®¤: -1)
  -status int         æŒ‰çŠ¶æ€è¿‡æ»¤ (-1è¡¨ç¤ºå…¨éƒ¨, é»˜è®¤: -1)

å¯¼å…¥é€‰é¡¹:
  -input string       è¾“å…¥æ–‡ä»¶è·¯å¾„ (å¿…éœ€)
  -skip-existing      è·³è¿‡å·²å­˜åœ¨çš„æ¸ é“ (é»˜è®¤: true)
  -update-existing    æ›´æ–°å·²å­˜åœ¨çš„æ¸ é“ (é»˜è®¤: false)
  -dry-run            æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…æ“ä½œæ•°æ®åº“

å¤‡ä»½/æ¢å¤é€‰é¡¹:
  -output string      å¤‡ä»½æ–‡ä»¶è·¯å¾„ (backupæ“ä½œ)
  -input string       æ¢å¤æ–‡ä»¶è·¯å¾„ (restoreæ“ä½œ)
  -dry-run            æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…æ“ä½œæ•°æ®åº“

Docker Compose æ•°æ®åº“è¿æ¥:
  é»˜è®¤è¿æ¥å­—ç¬¦ä¸²: root:123456@tcp(localhost:3306)/new-api
  å¦‚æœä½¿ç”¨ Docker Composeï¼Œè¯·ç¡®ä¿ MySQL ç«¯å£å·²æ˜ å°„åˆ°ä¸»æœº

ç¤ºä¾‹ç”¨æ³•:
  # å¯¼å‡ºæ‰€æœ‰æ¸ é“
  go run channel_manager.go -action=export

  # å¯¼å‡ºä¸ºCSVæ ¼å¼
  go run channel_manager.go -action=export -format=csv

  # å¤‡ä»½æ‰€æœ‰æ¸ é“æ•°æ®
  go run channel_manager.go -action=backup

  # ä»å¤‡ä»½æ–‡ä»¶æ¢å¤
  go run channel_manager.go -action=restore -input=backup.json

  # å¯¼å…¥æ¸ é“æ•°æ®ï¼ˆè·³è¿‡é‡å¤ï¼‰
  go run channel_manager.go -action=import -input=channels.json

  # å¯¼å…¥å¹¶æ›´æ–°å·²å­˜åœ¨çš„æ¸ é“
  go run channel_manager.go -action=import -input=channels.json -update-existing

  # æ¨¡æ‹Ÿå¯¼å…¥ï¼ˆä¸å®é™…æ“ä½œï¼‰
  go run channel_manager.go -action=import -input=channels.json -dry-run`)
}

// connectDB å·²ç§»è‡³ common åŒ…

func handleExport(db *gorm.DB, outputFile, format string, maskKeys bool, filterType, filterStatus int, verbose bool) error {
	channels, err := getAllChannels(db, filterType, filterStatus)
	if err != nil {
		return fmt.Errorf("è·å–æ¸ é“æ•°æ®å¤±è´¥: %v", err)
	}

	if verbose {
		log.Printf("æ‰¾åˆ° %d ä¸ªæ¸ é“", len(channels))
	}

	if maskKeys {
		maskSensitiveData(channels)
	}

	outputPath := outputFile
	if outputPath == "" {
		timestamp := time.Now().Format("20060102_150405")
		switch format {
		case "csv":
			outputPath = fmt.Sprintf("channels_export_%s.csv", timestamp)
		case "txt":
			outputPath = fmt.Sprintf("channels_export_%s.txt", timestamp)
		default:
			outputPath = fmt.Sprintf("channels_export_%s.json", timestamp)
		}
	}

	if err := os.MkdirAll(filepath.Dir(outputPath), 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %v", err)
	}

	switch format {
	case "csv":
		err = exportToCSV(channels, outputPath)
	case "txt":
		err = exportToTXT(channels, outputPath)
	default:
		err = exportToJSON(channels, outputPath)
	}

	if err != nil {
		return fmt.Errorf("å¯¼å‡ºæ•°æ®å¤±è´¥: %v", err)
	}

	fmt.Printf("âœ… æˆåŠŸå¯¼å‡º %d ä¸ªæ¸ é“åˆ°æ–‡ä»¶: %s\n", len(channels), outputPath)
	return nil
}

func handleBackup(db *gorm.DB, outputFile string, verbose bool) error {
	channels, err := getAllChannels(db, -1, -1)
	if err != nil {
		return fmt.Errorf("è·å–æ¸ é“æ•°æ®å¤±è´¥: %v", err)
	}

	if verbose {
		log.Printf("å¤‡ä»½ %d ä¸ªæ¸ é“", len(channels))
	}

	outputPath := outputFile
	if outputPath == "" {
		timestamp := time.Now().Format("20060102_150405")
		outputPath = fmt.Sprintf("channels_backup_%s.json", timestamp)
	}

	backupData := ChannelBackupData{
		ExportTime:    time.Now().Format("2006-01-02 15:04:05"),
		ExportVersion: "1.0.0",
		TotalChannels: len(channels),
		DatabaseInfo:  "MySQL Docker Compose",
		Channels:      channels,
	}

	file, err := os.Create(outputPath)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºå¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", err)
	}
	defer file.Close()

	encoder := json.NewEncoder(file)
	encoder.SetIndent("", "  ")
	if err := encoder.Encode(backupData); err != nil {
		return fmt.Errorf("å†™å…¥å¤‡ä»½æ•°æ®å¤±è´¥: %v", err)
	}

	fmt.Printf("âœ… æˆåŠŸå¤‡ä»½ %d ä¸ªæ¸ é“åˆ°æ–‡ä»¶: %s\n", len(channels), outputPath)
	return nil
}

func handleImport(db *gorm.DB, inputFile string, skipExisting, updateExisting, dryRun, verbose bool) error {
	if inputFile == "" {
		return fmt.Errorf("å¯¼å…¥æ“ä½œå¿…é¡»æŒ‡å®šè¾“å…¥æ–‡ä»¶ (-input)")
	}

	data, err := loadImportData(inputFile)
	if err != nil {
		return fmt.Errorf("åŠ è½½å¯¼å…¥æ–‡ä»¶å¤±è´¥: %v", err)
	}

	if verbose {
		log.Printf("å‡†å¤‡å¯¼å…¥ %d ä¸ªæ¸ é“", len(data.Channels))
	}

	result := &ImportResult{}
	result.Total = len(data.Channels)

	for _, channel := range data.Channels {
		if err := processChannelImport(db, channel, skipExisting, updateExisting, dryRun, verbose, result); err != nil {
			result.Errors = append(result.Errors, fmt.Sprintf("æ¸ é“ %s (ID:%d): %v", channel.Name, channel.Id, err))
			result.Failed++
		} else {
			result.Success++
		}
	}

	printImportResult(result, dryRun)
	return nil
}

func handleRestore(db *gorm.DB, inputFile string, dryRun, verbose bool) error {
	if inputFile == "" {
		return fmt.Errorf("æ¢å¤æ“ä½œå¿…é¡»æŒ‡å®šè¾“å…¥æ–‡ä»¶ (-input)")
	}

	data, err := loadImportData(inputFile)
	if err != nil {
		return fmt.Errorf("åŠ è½½æ¢å¤æ–‡ä»¶å¤±è´¥: %v", err)
	}

	if verbose {
		log.Printf("å‡†å¤‡æ¢å¤ %d ä¸ªæ¸ é“", len(data.Channels))
		log.Printf("å¤‡ä»½ä¿¡æ¯: %s, ç‰ˆæœ¬: %s", data.ExportTime, data.ExportVersion)
	}

	if !dryRun {
		// åœ¨æ¢å¤å‰å…ˆå¤‡ä»½å½“å‰æ•°æ®
		backupFile := fmt.Sprintf("pre_restore_backup_%s.json", time.Now().Format("20060102_150405"))
		if err := handleBackup(db, backupFile, false); err != nil {
			log.Printf("âš ï¸ åˆ›å»ºæ¢å¤å‰å¤‡ä»½å¤±è´¥: %v", err)
		} else {
			log.Printf("âœ… å·²åˆ›å»ºæ¢å¤å‰å¤‡ä»½: %s", backupFile)
		}

		// åˆ é™¤ç°æœ‰æ¸ é“æ•°æ®
		if err := db.Exec("DELETE FROM channels").Error; err != nil {
			return fmt.Errorf("æ¸…ç©ºç°æœ‰æ¸ é“æ•°æ®å¤±è´¥: %v", err)
		}
		if verbose {
			log.Printf("å·²æ¸…ç©ºç°æœ‰æ¸ é“æ•°æ®")
		}
	}

	result := &ImportResult{}
	result.Total = len(data.Channels)

	for _, channel := range data.Channels {
		if !dryRun {
			if err := db.Create(&channel).Error; err != nil {
				result.Errors = append(result.Errors, fmt.Sprintf("æ¢å¤æ¸ é“ %s (ID:%d): %v", channel.Name, channel.Id, err))
				result.Failed++
			} else {
				result.Success++
			}
		} else {
			result.Success++
		}
	}

	printRestoreResult(result, dryRun)
	return nil
}

func loadImportData(inputFile string) (*ChannelBackupData, error) {
	file, err := os.Open(inputFile)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	var data ChannelBackupData
	decoder := json.NewDecoder(file)
	if err := decoder.Decode(&data); err != nil {
		return nil, err
	}

	return &data, nil
}

func processChannelImport(db *gorm.DB, channel Channel, skipExisting, updateExisting, dryRun, verbose bool, result *ImportResult) error {
	// æ£€æŸ¥æ¸ é“æ˜¯å¦å·²å­˜åœ¨
	var existingChannel Channel
	err := db.Where("name = ? OR (id = ? AND id > 0)", channel.Name, channel.Id).First(&existingChannel).Error

	exists := err == nil

	if exists && skipExisting && !updateExisting {
		if verbose {
			log.Printf("è·³è¿‡å·²å­˜åœ¨çš„æ¸ é“: %s (ID:%d)", channel.Name, channel.Id)
		}
		result.Skipped++
		return nil
	}

	if !dryRun {
		if exists && updateExisting {
			// æ›´æ–°ç°æœ‰æ¸ é“
			channel.Id = existingChannel.Id // ä¿æŒåŸæœ‰ID
			if err := db.Save(&channel).Error; err != nil {
				return err
			}
			if verbose {
				log.Printf("æ›´æ–°æ¸ é“: %s (ID:%d)", channel.Name, channel.Id)
			}
		} else if !exists {
			// åˆ›å»ºæ–°æ¸ é“
			channel.Id = 0 // è®©æ•°æ®åº“è‡ªåŠ¨åˆ†é…ID
			if err := db.Create(&channel).Error; err != nil {
				return err
			}
			if verbose {
				log.Printf("åˆ›å»ºæ–°æ¸ é“: %s (ID:%d)", channel.Name, channel.Id)
			}
		}
	} else {
		if exists && updateExisting {
			if verbose {
				log.Printf("[æ¨¡æ‹Ÿ] æ›´æ–°æ¸ é“: %s", channel.Name)
			}
		} else if !exists {
			if verbose {
				log.Printf("[æ¨¡æ‹Ÿ] åˆ›å»ºæ–°æ¸ é“: %s", channel.Name)
			}
		}
	}

	return nil
}

func printImportResult(result *ImportResult, dryRun bool) {
	action := "å¯¼å…¥"
	if dryRun {
		action = "æ¨¡æ‹Ÿå¯¼å…¥"
	}

	fmt.Printf("\nğŸ“Š %sç»“æœç»Ÿè®¡:\n", action)
	fmt.Printf("æ€»è®¡: %d\n", result.Total)
	fmt.Printf("æˆåŠŸ: %d\n", result.Success)
	fmt.Printf("å¤±è´¥: %d\n", result.Failed)
	fmt.Printf("è·³è¿‡: %d\n", result.Skipped)

	if len(result.Errors) > 0 {
		fmt.Printf("\nâŒ é”™è¯¯è¯¦æƒ…:\n")
		for _, err := range result.Errors {
			fmt.Printf("  - %s\n", err)
		}
	}

	if dryRun {
		fmt.Printf("\nğŸ’¡ è¿™æ˜¯æ¨¡æ‹Ÿè¿è¡Œï¼Œæ²¡æœ‰å®é™…ä¿®æ”¹æ•°æ®åº“\n")
	}
}

func printRestoreResult(result *ImportResult, dryRun bool) {
	action := "æ¢å¤"
	if dryRun {
		action = "æ¨¡æ‹Ÿæ¢å¤"
	}

	fmt.Printf("\nğŸ“Š %sç»“æœç»Ÿè®¡:\n", action)
	fmt.Printf("æ€»è®¡: %d\n", result.Total)
	fmt.Printf("æˆåŠŸ: %d\n", result.Success)
	fmt.Printf("å¤±è´¥: %d\n", result.Failed)

	if len(result.Errors) > 0 {
		fmt.Printf("\nâŒ é”™è¯¯è¯¦æƒ…:\n")
		for _, err := range result.Errors {
			fmt.Printf("  - %s\n", err)
		}
	}

	if dryRun {
		fmt.Printf("\nğŸ’¡ è¿™æ˜¯æ¨¡æ‹Ÿè¿è¡Œï¼Œæ²¡æœ‰å®é™…ä¿®æ”¹æ•°æ®åº“\n")
	} else {
		fmt.Printf("\nâœ… æ•°æ®åº“å·²æ¢å¤åˆ°å¤‡ä»½çŠ¶æ€\n")
	}
}

// ä»¥ä¸‹å‡½æ•°å¤ç”¨ä¹‹å‰çš„ä»£ç 
func getAllChannels(db *gorm.DB, filterType, filterStatus int) ([]Channel, error) {
	var channels []Channel

	query := db

	if filterType >= 0 {
		query = query.Where("type = ?", filterType)
	}

	if filterStatus >= 0 {
		query = query.Where("status = ?", filterStatus)
	}

	if err := query.Find(&channels).Error; err != nil {
		return nil, err
	}

	return channels, nil
}

func maskSensitiveData(channels []Channel) {
	for i := range channels {
		if channels[i].Key != "" {
			channels[i].Key = common.MaskString(channels[i].Key)
		}
		if channels[i].Other != "" {
			channels[i].Other = common.MaskString(channels[i].Other)
		}
	}
}

func maskDSN(dsn string) string {
	return common.MaskDSN(dsn)
}

func exportToJSON(channels []Channel, outputPath string) error {
	exportData := ChannelBackupData{
		ExportTime:    time.Now().Format("2006-01-02 15:04:05"),
		ExportVersion: "1.0.0",
		TotalChannels: len(channels),
		DatabaseInfo:  "Export",
		Channels:      channels,
	}

	file, err := os.Create(outputPath)
	if err != nil {
		return err
	}
	defer file.Close()

	encoder := json.NewEncoder(file)
	encoder.SetIndent("", "  ")
	return encoder.Encode(exportData)
}

func exportToCSV(channels []Channel, outputPath string) error {
	file, err := os.Create(outputPath)
	if err != nil {
		return err
	}
	defer file.Close()

	headers := []string{
		"ID", "Name", "Type", "TypeName", "Status", "StatusName", "Group", "Weight",
		"Priority", "Balance", "UsedQuota", "Models", "BaseURL", "CreatedTime", "TestTime",
		"ResponseTime", "Tag", "Key", "Other", "Setting",
	}

	file.WriteString(strings.Join(headers, ",") + "\n")

	for _, channel := range channels {
		row := []string{
			strconv.Itoa(channel.Id),
			fmt.Sprintf(`"%s"`, channel.Name),
			strconv.Itoa(channel.Type),
			fmt.Sprintf(`"%s"`, getChannelTypeName(channel.Type)),
			strconv.Itoa(channel.Status),
			fmt.Sprintf(`"%s"`, getChannelStatusName(channel.Status)),
			fmt.Sprintf(`"%s"`, channel.Group),
			formatUintPtr(channel.Weight),
			formatInt64Ptr(channel.Priority),
			fmt.Sprintf("%.2f", channel.Balance),
			strconv.FormatInt(channel.UsedQuota, 10),
			fmt.Sprintf(`"%s"`, channel.Models),
			formatStringPtr(channel.BaseURL),
			formatTimestamp(channel.CreatedTime),
			formatTimestamp(channel.TestTime),
			strconv.Itoa(channel.ResponseTime),
			formatStringPtr(channel.Tag),
			fmt.Sprintf(`"%s"`, channel.Key),
			fmt.Sprintf(`"%s"`, channel.Other),
			formatStringPtr(channel.Setting),
		}

		file.WriteString(strings.Join(row, ",") + "\n")
	}

	return nil
}

func exportToTXT(channels []Channel, outputPath string) error {
	file, err := os.Create(outputPath)
	if err != nil {
		return err
	}
	defer file.Close()

	file.WriteString(fmt.Sprintf("æ¸ é“å¯¼å‡ºæŠ¥å‘Š - %s\n", time.Now().Format("2006-01-02 15:04:05")))
	file.WriteString(fmt.Sprintf("æ€»è®¡: %d ä¸ªæ¸ é“\n\n", len(channels)))
	file.WriteString(strings.Repeat("=", 80) + "\n\n")

	for _, channel := range channels {
		file.WriteString(fmt.Sprintf("æ¸ é“ID: %d\n", channel.Id))
		file.WriteString(fmt.Sprintf("åç§°: %s\n", channel.Name))
		file.WriteString(fmt.Sprintf("ç±»å‹: %s (%d)\n", getChannelTypeName(channel.Type), channel.Type))
		file.WriteString(fmt.Sprintf("çŠ¶æ€: %s (%d)\n", getChannelStatusName(channel.Status), channel.Status))
		file.WriteString(fmt.Sprintf("åˆ†ç»„: %s\n", channel.Group))

		if channel.Weight != nil {
			file.WriteString(fmt.Sprintf("æƒé‡: %d\n", *channel.Weight))
		}
		if channel.Priority != nil {
			file.WriteString(fmt.Sprintf("ä¼˜å…ˆçº§: %d\n", *channel.Priority))
		}

		file.WriteString(fmt.Sprintf("ä½™é¢: %.2f USD\n", channel.Balance))
		file.WriteString(fmt.Sprintf("å·²ç”¨é¢åº¦: %d\n", channel.UsedQuota))
		file.WriteString(fmt.Sprintf("æ”¯æŒæ¨¡å‹: %s\n", channel.Models))

		if channel.BaseURL != nil && *channel.BaseURL != "" {
			file.WriteString(fmt.Sprintf("åŸºç¡€URL: %s\n", *channel.BaseURL))
		}

		if channel.Tag != nil && *channel.Tag != "" {
			file.WriteString(fmt.Sprintf("æ ‡ç­¾: %s\n", *channel.Tag))
		}

		file.WriteString(fmt.Sprintf("åˆ›å»ºæ—¶é—´: %s\n", formatTimestamp(channel.CreatedTime)))
		file.WriteString(fmt.Sprintf("æœ€åæµ‹è¯•: %s\n", formatTimestamp(channel.TestTime)))

		if channel.ResponseTime > 0 {
			file.WriteString(fmt.Sprintf("å“åº”æ—¶é—´: %d ms\n", channel.ResponseTime))
		}

		file.WriteString(fmt.Sprintf("APIå¯†é’¥: %s\n", channel.Key))

		if channel.Setting != nil && *channel.Setting != "" {
			file.WriteString(fmt.Sprintf("è®¾ç½®: %s\n", *channel.Setting))
		}

		file.WriteString("\n" + strings.Repeat("-", 80) + "\n\n")
	}

	return nil
}

func getChannelTypeName(typeId int) string {
	if name, exists := ChannelTypeNames[typeId]; exists {
		return name
	}
	return fmt.Sprintf("Unknown (%d)", typeId)
}

func getChannelStatusName(status int) string {
	if name, exists := ChannelStatusNames[status]; exists {
		return name
	}
	return fmt.Sprintf("Unknown (%d)", status)
}

func formatStringPtr(s *string) string {
	if s == nil {
		return `""`
	}
	return fmt.Sprintf(`"%s"`, *s)
}

func formatUintPtr(u *uint) string {
	if u == nil {
		return "0"
	}
	return strconv.FormatUint(uint64(*u), 10)
}

func formatInt64Ptr(i *int64) string {
	if i == nil {
		return "0"
	}
	return strconv.FormatInt(*i, 10)
}

func formatTimestamp(ts int64) string {
	if ts == 0 {
		return `""`
	}
	return fmt.Sprintf(`"%s"`, time.Unix(ts, 0).Format("2006-01-02 15:04:05"))
}
